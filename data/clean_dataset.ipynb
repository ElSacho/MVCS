{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to processed_data/rf1.npz\n",
      "X shape: (9125, 64)\n",
      "Y shape: (9125, 8)\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (9125, 64)\n",
      "  - Nombre de NaN: 3264\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 9005\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (9125, 8)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 9125\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Traitement de la clé: X\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Traitement de la clé: Y\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Fichier enregistré sous 'processed_data/rf1.npz'.\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (9125, 64)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 9125\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (9125, 8)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 9125\n",
      "  - Nombre de NaN dans la colonne 0: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import arff\n",
    "\n",
    "def process_and_save_data_arff(input_path, output_path):\n",
    "    # Charger le dataset depuis le fichier ARFF\n",
    "    data, meta = arff.loadarff(input_path)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Convertir les colonnes de type byte en string si nécessaire\n",
    "    for column in df.select_dtypes([np.object_]):\n",
    "        df[column] = df[column].str.decode('utf-8')\n",
    "    \n",
    "    # Séparer les caractéristiques (X) et les cibles (Y)\n",
    "    X = df.iloc[:, :-8].values  # Modifier en fonction de la structure des données\n",
    "    Y = df.iloc[:, -8:].values  # Modifier en fonction de la structure des données\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier compressé\n",
    "    np.savez_compressed(output_path, X=X, Y=Y)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données depuis le fichier compressé\n",
    "    data = np.load(file_path)\n",
    "    return data['X'], data['Y']\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_path_arff = \"data_brut/rf1.arff\"\n",
    "output_path_arff = \"processed_data/rf1.npz\"\n",
    "\n",
    "# Créer le dossier de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(output_path_arff), exist_ok=True)\n",
    "\n",
    "# Process et sauvegarde\n",
    "process_and_save_data_arff(input_path_arff, output_path_arff)\n",
    "\n",
    "# Exemple d'utilisation du loader\n",
    "X, Y = load_data(output_path_arff)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(\"processed_data/rf1.npz\")\n",
    "\n",
    "# Afficher les clés disponibles\n",
    "print(\"Clés disponibles dans le fichier :\", list(data.keys()))\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        continue\n",
    "\n",
    "    # Vérification des NaN et Inf uniquement si le type est float\n",
    "    if np.issubdtype(array.dtype, np.floating):\n",
    "        nan_count = np.isnan(array).sum()\n",
    "        inf_count = np.isinf(array).sum()\n",
    "    else:\n",
    "        nan_count = inf_count = 0\n",
    "\n",
    "    print(f\"\\nClé: {key}\")\n",
    "    print(f\"  - Forme: {array.shape}\")\n",
    "    print(f\"  - Nombre de NaN: {nan_count}\")\n",
    "    print(f\"  - Nombre de Inf: {inf_count}\")\n",
    "\n",
    "    # Si le tableau est 2D, analyse plus fine\n",
    "    if array.ndim == 2:\n",
    "        # Nombre de lignes sans aucun NaN\n",
    "        rows_without_nan = np.sum(~np.isnan(array).any(axis=1))\n",
    "        print(f\"  - Nombre de lignes sans aucun NaN: {rows_without_nan}\")\n",
    "\n",
    "        # Sélectionner une colonne spécifique (ex: colonne 0)\n",
    "        col_idx = 0  # Modifier cette valeur pour une autre colonne\n",
    "        if col_idx < array.shape[1]:  # Vérifier que l'index est valide\n",
    "            nan_in_column = np.isnan(array[:, col_idx]).sum()\n",
    "            print(f\"  - Nombre de NaN dans la colonne {col_idx}: {nan_in_column}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(\"processed_data/rf1.npz\")\n",
    "\n",
    "# Dictionnaire pour stocker les données modifiées\n",
    "modified_data = {}\n",
    "\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        modified_data[key] = array\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTraitement de la clé: {key}\")\n",
    "    \n",
    "    # Si c'est un tableau 2D avec des nombres flottants\n",
    "    if array.ndim == 2 and np.issubdtype(array.dtype, np.floating):\n",
    "        # Remplacement des NaN colonne par colonne\n",
    "        for col_idx in range(array.shape[1]):\n",
    "            col = array[:, col_idx]\n",
    "            if np.isnan(col).any():  # Vérifier s'il y a des NaN\n",
    "                mean_value = np.nanmean(col)  # Moyenne des valeurs non NaN\n",
    "                col[np.isnan(col)] = mean_value  # Remplacer NaN par la moyenne\n",
    "        print(f\"  - NaN remplacés par la moyenne dans toutes les colonnes.\")\n",
    "    \n",
    "    modified_data[key] = array  # Sauvegarde du tableau modifié\n",
    "\n",
    "# Enregistrer les données modifiées\n",
    "np.savez(\"processed_data/rf1.npz\", **modified_data)\n",
    "print(\"\\nFichier enregistré sous 'processed_data/rf1.npz'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to processed_data/rf2.npz\n",
      "X shape: (9125, 576)\n",
      "Y shape: (9125, 8)\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (9125, 576)\n",
      "  - Nombre de NaN: 356160\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 7679\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (9125, 8)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 9125\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Traitement de la clé: X\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Traitement de la clé: Y\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Fichier enregistré sous 'processed_data/rf2.npz'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import arff\n",
    "\n",
    "def process_and_save_data_arff(input_path, output_path):\n",
    "    # Charger le dataset depuis le fichier ARFF\n",
    "    data, meta = arff.loadarff(input_path)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Convertir les colonnes de type byte en string si nécessaire\n",
    "    for column in df.select_dtypes([np.object_]):\n",
    "        df[column] = df[column].str.decode('utf-8')\n",
    "    \n",
    "    # Séparer les caractéristiques (X) et les cibles (Y)\n",
    "    X = df.iloc[:, :-8].values  # Modifier en fonction de la structure des données\n",
    "    Y = df.iloc[:, -8:].values  # Modifier en fonction de la structure des données\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier compressé\n",
    "    np.savez_compressed(output_path, X=X, Y=Y)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données depuis le fichier compressé\n",
    "    data = np.load(file_path)\n",
    "    return data['X'], data['Y']\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_path_arff = \"data_brut/rf2.arff\"\n",
    "output_path_arff = \"processed_data/rf2.npz\"\n",
    "\n",
    "# Créer le dossier de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(output_path_arff), exist_ok=True)\n",
    "\n",
    "# Process et sauvegarde\n",
    "process_and_save_data_arff(input_path_arff, output_path_arff)\n",
    "\n",
    "# Exemple d'utilisation du loader\n",
    "X, Y = load_data(output_path_arff)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(\"processed_data/rf2.npz\")\n",
    "\n",
    "# Afficher les clés disponibles\n",
    "print(\"Clés disponibles dans le fichier :\", list(data.keys()))\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        continue\n",
    "\n",
    "    # Vérification des NaN et Inf uniquement si le type est float\n",
    "    if np.issubdtype(array.dtype, np.floating):\n",
    "        nan_count = np.isnan(array).sum()\n",
    "        inf_count = np.isinf(array).sum()\n",
    "    else:\n",
    "        nan_count = inf_count = 0\n",
    "\n",
    "    print(f\"\\nClé: {key}\")\n",
    "    print(f\"  - Forme: {array.shape}\")\n",
    "    print(f\"  - Nombre de NaN: {nan_count}\")\n",
    "    print(f\"  - Nombre de Inf: {inf_count}\")\n",
    "\n",
    "    # Si le tableau est 2D, analyse plus fine\n",
    "    if array.ndim == 2:\n",
    "        # Nombre de lignes sans aucun NaN\n",
    "        rows_without_nan = np.sum(~np.isnan(array).any(axis=1))\n",
    "        print(f\"  - Nombre de lignes sans aucun NaN: {rows_without_nan}\")\n",
    "\n",
    "        # Sélectionner une colonne spécifique (ex: colonne 0)\n",
    "        col_idx = 0  # Modifier cette valeur pour une autre colonne\n",
    "        if col_idx < array.shape[1]:  # Vérifier que l'index est valide\n",
    "            nan_in_column = np.isnan(array[:, col_idx]).sum()\n",
    "            print(f\"  - Nombre de NaN dans la colonne {col_idx}: {nan_in_column}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(\"processed_data/rf2.npz\")\n",
    "\n",
    "# Dictionnaire pour stocker les données modifiées\n",
    "modified_data = {}\n",
    "\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        modified_data[key] = array\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTraitement de la clé: {key}\")\n",
    "    \n",
    "    # Si c'est un tableau 2D avec des nombres flottants\n",
    "    if array.ndim == 2 and np.issubdtype(array.dtype, np.floating):\n",
    "        # Remplacement des NaN colonne par colonne\n",
    "        for col_idx in range(array.shape[1]):\n",
    "            col = array[:, col_idx]\n",
    "            if np.isnan(col).any():  # Vérifier s'il y a des NaN\n",
    "                mean_value = np.nanmean(col)  # Moyenne des valeurs non NaN\n",
    "                col[np.isnan(col)] = mean_value  # Remplacer NaN par la moyenne\n",
    "        print(f\"  - NaN remplacés par la moyenne dans toutes les colonnes.\")\n",
    "    \n",
    "    modified_data[key] = array  # Sauvegarde du tableau modifié\n",
    "\n",
    "# Enregistrer les données modifiées\n",
    "np.savez(\"processed_data/rf2.npz\", **modified_data)\n",
    "print(\"\\nFichier enregistré sous 'processed_data/rf2.npz'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to processed_data/scm1d.npz\n",
      "X shape: (9803, 280)\n",
      "Y shape: (9803, 16)\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (9803, 280)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 9803\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (9803, 16)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 9803\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Traitement de la clé: X\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Traitement de la clé: Y\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Fichier enregistré sous 'processed_data/scm1d.npz'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import arff\n",
    "\n",
    "def process_and_save_data_arff(input_path, output_path):\n",
    "    # Charger le dataset depuis le fichier ARFF\n",
    "    data, meta = arff.loadarff(input_path)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Convertir les colonnes de type byte en string si nécessaire\n",
    "    for column in df.select_dtypes([np.object_]):\n",
    "        df[column] = df[column].str.decode('utf-8')\n",
    "    \n",
    "    # Séparer les caractéristiques (X) et les cibles (Y)\n",
    "    X = df.iloc[:, :-16].values  # Modifier en fonction de la structure des données\n",
    "    Y = df.iloc[:, -16:].values  # Modifier en fonction de la structure des données\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier compressé\n",
    "    np.savez_compressed(output_path, X=X, Y=Y)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données depuis le fichier compressé\n",
    "    data = np.load(file_path)\n",
    "    return data['X'], data['Y']\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_path_arff = \"data_brut/scm1d.arff\"\n",
    "output_path_arff = \"processed_data/scm1d.npz\"\n",
    "\n",
    "# Créer le dossier de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(output_path_arff), exist_ok=True)\n",
    "\n",
    "# Process et sauvegarde\n",
    "process_and_save_data_arff(input_path_arff, output_path_arff)\n",
    "\n",
    "# Exemple d'utilisation du loader\n",
    "X, Y = load_data(output_path_arff)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(\"processed_data/scm1d.npz\")\n",
    "\n",
    "# Afficher les clés disponibles\n",
    "print(\"Clés disponibles dans le fichier :\", list(data.keys()))\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        continue\n",
    "\n",
    "    # Vérification des NaN et Inf uniquement si le type est float\n",
    "    if np.issubdtype(array.dtype, np.floating):\n",
    "        nan_count = np.isnan(array).sum()\n",
    "        inf_count = np.isinf(array).sum()\n",
    "    else:\n",
    "        nan_count = inf_count = 0\n",
    "\n",
    "    print(f\"\\nClé: {key}\")\n",
    "    print(f\"  - Forme: {array.shape}\")\n",
    "    print(f\"  - Nombre de NaN: {nan_count}\")\n",
    "    print(f\"  - Nombre de Inf: {inf_count}\")\n",
    "\n",
    "    # Si le tableau est 2D, analyse plus fine\n",
    "    if array.ndim == 2:\n",
    "        # Nombre de lignes sans aucun NaN\n",
    "        rows_without_nan = np.sum(~np.isnan(array).any(axis=1))\n",
    "        print(f\"  - Nombre de lignes sans aucun NaN: {rows_without_nan}\")\n",
    "\n",
    "        # Sélectionner une colonne spécifique (ex: colonne 0)\n",
    "        col_idx = 0  # Modifier cette valeur pour une autre colonne\n",
    "        if col_idx < array.shape[1]:  # Vérifier que l'index est valide\n",
    "            nan_in_column = np.isnan(array[:, col_idx]).sum()\n",
    "            print(f\"  - Nombre de NaN dans la colonne {col_idx}: {nan_in_column}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(\"processed_data/scm1d.npz\")\n",
    "\n",
    "# Dictionnaire pour stocker les données modifiées\n",
    "modified_data = {}\n",
    "\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        modified_data[key] = array\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTraitement de la clé: {key}\")\n",
    "    \n",
    "    # Si c'est un tableau 2D avec des nombres flottants\n",
    "    if array.ndim == 2 and np.issubdtype(array.dtype, np.floating):\n",
    "        # Remplacement des NaN colonne par colonne\n",
    "        for col_idx in range(array.shape[1]):\n",
    "            col = array[:, col_idx]\n",
    "            if np.isnan(col).any():  # Vérifier s'il y a des NaN\n",
    "                mean_value = np.nanmean(col)  # Moyenne des valeurs non NaN\n",
    "                col[np.isnan(col)] = mean_value  # Remplacer NaN par la moyenne\n",
    "        print(f\"  - NaN remplacés par la moyenne dans toutes les colonnes.\")\n",
    "    \n",
    "    modified_data[key] = array  # Sauvegarde du tableau modifié\n",
    "\n",
    "# Enregistrer les données modifiées\n",
    "np.savez(\"processed_data/scm1d.npz\", **modified_data)\n",
    "print(\"\\nFichier enregistré sous 'processed_data/scm1d.npz'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to processed_data/scm20d.npz\n",
      "X shape: (8966, 61)\n",
      "Y shape: (8966, 16)\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (8966, 61)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 8966\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (8966, 16)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 8966\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Traitement de la clé: X\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Traitement de la clé: Y\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Fichier enregistré sous 'processed_data/scm20d.npz'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import arff\n",
    "\n",
    "def process_and_save_data_arff(input_path, output_path):\n",
    "    # Charger le dataset depuis le fichier ARFF\n",
    "    data, meta = arff.loadarff(input_path)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Convertir les colonnes de type byte en string si nécessaire\n",
    "    for column in df.select_dtypes([np.object_]):\n",
    "        df[column] = df[column].str.decode('utf-8')\n",
    "    \n",
    "    # Séparer les caractéristiques (X) et les cibles (Y)\n",
    "    X = df.iloc[:, :-16].values  # Modifier en fonction de la structure des données\n",
    "    Y = df.iloc[:, -16:].values  # Modifier en fonction de la structure des données\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier compressé\n",
    "    np.savez_compressed(output_path, X=X, Y=Y)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données depuis le fichier compressé\n",
    "    data = np.load(file_path)\n",
    "    return data['X'], data['Y']\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_path_arff = \"data_brut/scm20d.arff\"\n",
    "output_path_arff = \"processed_data/scm20d.npz\"\n",
    "\n",
    "# Créer le dossier de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(output_path_arff), exist_ok=True)\n",
    "\n",
    "# Process et sauvegarde\n",
    "process_and_save_data_arff(input_path_arff, output_path_arff)\n",
    "\n",
    "# Exemple d'utilisation du loader\n",
    "X, Y = load_data(output_path_arff)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path_arff)\n",
    "\n",
    "# Afficher les clés disponibles\n",
    "print(\"Clés disponibles dans le fichier :\", list(data.keys()))\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        continue\n",
    "\n",
    "    # Vérification des NaN et Inf uniquement si le type est float\n",
    "    if np.issubdtype(array.dtype, np.floating):\n",
    "        nan_count = np.isnan(array).sum()\n",
    "        inf_count = np.isinf(array).sum()\n",
    "    else:\n",
    "        nan_count = inf_count = 0\n",
    "\n",
    "    print(f\"\\nClé: {key}\")\n",
    "    print(f\"  - Forme: {array.shape}\")\n",
    "    print(f\"  - Nombre de NaN: {nan_count}\")\n",
    "    print(f\"  - Nombre de Inf: {inf_count}\")\n",
    "\n",
    "    # Si le tableau est 2D, analyse plus fine\n",
    "    if array.ndim == 2:\n",
    "        # Nombre de lignes sans aucun NaN\n",
    "        rows_without_nan = np.sum(~np.isnan(array).any(axis=1))\n",
    "        print(f\"  - Nombre de lignes sans aucun NaN: {rows_without_nan}\")\n",
    "\n",
    "        # Sélectionner une colonne spécifique (ex: colonne 0)\n",
    "        col_idx = 0  # Modifier cette valeur pour une autre colonne\n",
    "        if col_idx < array.shape[1]:  # Vérifier que l'index est valide\n",
    "            nan_in_column = np.isnan(array[:, col_idx]).sum()\n",
    "            print(f\"  - Nombre de NaN dans la colonne {col_idx}: {nan_in_column}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(\"processed_data/scm20d.npz\")\n",
    "\n",
    "# Dictionnaire pour stocker les données modifiées\n",
    "modified_data = {}\n",
    "\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        modified_data[key] = array\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTraitement de la clé: {key}\")\n",
    "    \n",
    "    # Si c'est un tableau 2D avec des nombres flottants\n",
    "    if array.ndim == 2 and np.issubdtype(array.dtype, np.floating):\n",
    "        # Remplacement des NaN colonne par colonne\n",
    "        for col_idx in range(array.shape[1]):\n",
    "            col = array[:, col_idx]\n",
    "            if np.isnan(col).any():  # Vérifier s'il y a des NaN\n",
    "                mean_value = np.nanmean(col)  # Moyenne des valeurs non NaN\n",
    "                col[np.isnan(col)] = mean_value  # Remplacer NaN par la moyenne\n",
    "        print(f\"  - NaN remplacés par la moyenne dans toutes les colonnes.\")\n",
    "    \n",
    "    modified_data[key] = array  # Sauvegarde du tableau modifié\n",
    "\n",
    "# Enregistrer les données modifiées\n",
    "np.savez(\"processed_data/scm20d.npz\", **modified_data)\n",
    "print(\"\\nFichier enregistré sous 'processed_data/scm20d.npz'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to processed_data/Bias_correction_ucl.npz\n",
      "X shape: (7752, 22)\n",
      "Y shape: (7752, 2)\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (7752, 22)\n",
      "  - Nombre de NaN: 1192\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 7605\n",
      "  - Nombre de NaN dans la colonne 0: 2\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (7752, 2)\n",
      "  - Nombre de NaN: 54\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 7725\n",
      "  - Nombre de NaN dans la colonne 0: 27\n",
      "\n",
      "Traitement de la clé: X\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Traitement de la clé: Y\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Fichier enregistré sous 'processed_data/Bias_correction_ucl.npz'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_and_save_data(input_path, output_path):\n",
    "    # Charger le dataset depuis le fichier CSV\n",
    "    data = pd.read_csv(input_path)\n",
    "    \n",
    "    # Séparer les caractéristiques (X) et les cibles (Y)\n",
    "    # X = data.drop(data.columns[[1, 2]], axis=1).values\n",
    "    # X = data.iloc[:, 8:23].values\n",
    "    # Y = data.iloc[:, [1, 2]].values\n",
    "    data = data.select_dtypes(include=[np.number])  # Ne garde que les colonnes numériques\n",
    "    X = data.iloc[:, :-2].values.astype(np.float32)  # Convertir en float\n",
    "    Y = data.iloc[:, -2:].values.astype(np.float32)  # Convertir en float\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier compressé\n",
    "    np.savez_compressed(output_path, X=X, Y=Y)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données depuis le fichier compressé\n",
    "    data = np.load(file_path)\n",
    "    return data['X'], data['Y']\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_path = \"data_brut/Bias_correction_ucl.csv\"\n",
    "output_path = \"processed_data/Bias_correction_ucl.npz\"\n",
    "\n",
    "# Créer le dossier de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Process et sauvegarde\n",
    "process_and_save_data(input_path, output_path)\n",
    "\n",
    "# Exemple d'utilisation du loader\n",
    "X, Y = load_data(output_path)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Afficher les clés disponibles\n",
    "print(\"Clés disponibles dans le fichier :\", list(data.keys()))\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        continue\n",
    "\n",
    "    # Vérification des NaN et Inf uniquement si le type est float\n",
    "    if np.issubdtype(array.dtype, np.floating):\n",
    "        nan_count = np.isnan(array).sum()\n",
    "        inf_count = np.isinf(array).sum()\n",
    "    else:\n",
    "        nan_count = inf_count = 0\n",
    "\n",
    "    print(f\"\\nClé: {key}\")\n",
    "    print(f\"  - Forme: {array.shape}\")\n",
    "    print(f\"  - Nombre de NaN: {nan_count}\")\n",
    "    print(f\"  - Nombre de Inf: {inf_count}\")\n",
    "\n",
    "    # Si le tableau est 2D, analyse plus fine\n",
    "    if array.ndim == 2:\n",
    "        # Nombre de lignes sans aucun NaN\n",
    "        rows_without_nan = np.sum(~np.isnan(array).any(axis=1))\n",
    "        print(f\"  - Nombre de lignes sans aucun NaN: {rows_without_nan}\")\n",
    "\n",
    "        # Sélectionner une colonne spécifique (ex: colonne 0)\n",
    "        col_idx = 0  # Modifier cette valeur pour une autre colonne\n",
    "        if col_idx < array.shape[1]:  # Vérifier que l'index est valide\n",
    "            nan_in_column = np.isnan(array[:, col_idx]).sum()\n",
    "            print(f\"  - Nombre de NaN dans la colonne {col_idx}: {nan_in_column}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Dictionnaire pour stocker les données modifiées\n",
    "modified_data = {}\n",
    "\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        modified_data[key] = array\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTraitement de la clé: {key}\")\n",
    "    \n",
    "    # Si c'est un tableau 2D avec des nombres flottants\n",
    "    if array.ndim == 2 and np.issubdtype(array.dtype, np.floating):\n",
    "        # Remplacement des NaN colonne par colonne\n",
    "        for col_idx in range(array.shape[1]):\n",
    "            col = array[:, col_idx]\n",
    "            if np.isnan(col).any():  # Vérifier s'il y a des NaN\n",
    "                mean_value = np.nanmean(col)  # Moyenne des valeurs non NaN\n",
    "                col[np.isnan(col)] = mean_value  # Remplacer NaN par la moyenne\n",
    "        print(f\"  - NaN remplacés par la moyenne dans toutes les colonnes.\")\n",
    "    \n",
    "    modified_data[key] = array  # Sauvegarde du tableau modifié\n",
    "\n",
    "# Enregistrer les données modifiées\n",
    "np.savez(output_path, **modified_data)\n",
    "print(f\"\\nFichier enregistré sous '{output_path}'.\")\n",
    "\n",
    "\n",
    "# https://archive.ics.uci.edu/dataset/514/bias+correction+of+numerical+prediction+model+temperature+forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to processed_data/CASP.npz\n",
      "X shape: (45730, 8)\n",
      "Y shape: (45730, 2)\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (45730, 8)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 45730\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (45730, 2)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 45730\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Traitement de la clé: X\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Traitement de la clé: Y\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Fichier enregistré sous 'processed_data/CASP.npz'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_and_save_data(input_path, output_path):\n",
    "    # Charger le dataset depuis le fichier CSV\n",
    "    data = pd.read_csv(input_path)\n",
    "    \n",
    "    # Séparer les caractéristiques (X) et les cibles (Y)\n",
    "    # X = data.drop(data.columns[[1, 2]], axis=1).values\n",
    "    # X = data.iloc[:, 8:23].values\n",
    "    # Y = data.iloc[:, [1, 2]].values\n",
    "    data = data.select_dtypes(include=[np.number])  # Ne garde que les colonnes numériques\n",
    "    X = data.iloc[:, :-2].values.astype(np.float32)  # Convertir en float\n",
    "    Y = data.iloc[:, -2:].values.astype(np.float32)  # Convertir en float\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier compressé\n",
    "    np.savez_compressed(output_path, X=X, Y=Y)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données depuis le fichier compressé\n",
    "    data = np.load(file_path)\n",
    "    return data['X'], data['Y']\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_path = \"data_brut/CASP.csv\"\n",
    "output_path = \"processed_data/CASP.npz\"\n",
    "\n",
    "# Créer le dossier de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Process et sauvegarde\n",
    "process_and_save_data(input_path, output_path)\n",
    "\n",
    "# Exemple d'utilisation du loader\n",
    "X, Y = load_data(output_path)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Afficher les clés disponibles\n",
    "print(\"Clés disponibles dans le fichier :\", list(data.keys()))\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        continue\n",
    "\n",
    "    # Vérification des NaN et Inf uniquement si le type est float\n",
    "    if np.issubdtype(array.dtype, np.floating):\n",
    "        nan_count = np.isnan(array).sum()\n",
    "        inf_count = np.isinf(array).sum()\n",
    "    else:\n",
    "        nan_count = inf_count = 0\n",
    "\n",
    "    print(f\"\\nClé: {key}\")\n",
    "    print(f\"  - Forme: {array.shape}\")\n",
    "    print(f\"  - Nombre de NaN: {nan_count}\")\n",
    "    print(f\"  - Nombre de Inf: {inf_count}\")\n",
    "\n",
    "    # Si le tableau est 2D, analyse plus fine\n",
    "    if array.ndim == 2:\n",
    "        # Nombre de lignes sans aucun NaN\n",
    "        rows_without_nan = np.sum(~np.isnan(array).any(axis=1))\n",
    "        print(f\"  - Nombre de lignes sans aucun NaN: {rows_without_nan}\")\n",
    "\n",
    "        # Sélectionner une colonne spécifique (ex: colonne 0)\n",
    "        col_idx = 0  # Modifier cette valeur pour une autre colonne\n",
    "        if col_idx < array.shape[1]:  # Vérifier que l'index est valide\n",
    "            nan_in_column = np.isnan(array[:, col_idx]).sum()\n",
    "            print(f\"  - Nombre de NaN dans la colonne {col_idx}: {nan_in_column}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Dictionnaire pour stocker les données modifiées\n",
    "modified_data = {}\n",
    "\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        modified_data[key] = array\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTraitement de la clé: {key}\")\n",
    "    \n",
    "    # Si c'est un tableau 2D avec des nombres flottants\n",
    "    if array.ndim == 2 and np.issubdtype(array.dtype, np.floating):\n",
    "        # Remplacement des NaN colonne par colonne\n",
    "        for col_idx in range(array.shape[1]):\n",
    "            col = array[:, col_idx]\n",
    "            if np.isnan(col).any():  # Vérifier s'il y a des NaN\n",
    "                mean_value = np.nanmean(col)  # Moyenne des valeurs non NaN\n",
    "                col[np.isnan(col)] = mean_value  # Remplacer NaN par la moyenne\n",
    "        print(f\"  - NaN remplacés par la moyenne dans toutes les colonnes.\")\n",
    "    \n",
    "    modified_data[key] = array  # Sauvegarde du tableau modifié\n",
    "\n",
    "# Enregistrer les données modifiées\n",
    "np.savez(output_path, **modified_data)\n",
    "print(f\"\\nFichier enregistré sous '{output_path}'.\")\n",
    "\n",
    "\n",
    "# https://github.com/Zhendong-Wang/Probabilistic-Conformal-Prediction/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to processed_data/taxi.npz\n",
      "X shape: (61286, 6)\n",
      "Y shape: (61286, 2)\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (61286, 6)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 61286\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (61286, 2)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 61286\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Traitement de la clé: X\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Traitement de la clé: Y\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Fichier enregistré sous 'processed_data/taxi.npz'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_and_save_data(input_path, output_path):\n",
    "    # Charger le dataset depuis le fichier CSV\n",
    "    data = pd.read_csv(input_path)\n",
    "    \n",
    "    # Séparer les caractéristiques (X) et les cibles (Y)\n",
    "    # X = data.drop(data.columns[[1, 2]], axis=1).values\n",
    "    # X = data.iloc[:, 8:23].values\n",
    "    # Y = data.iloc[:, [1, 2]].values\n",
    "    data = data.select_dtypes(include=[np.number])  # Ne garde que les colonnes numériques\n",
    "    X = data.iloc[:, :-2].values.astype(np.float32)  # Convertir en float\n",
    "    Y = data.iloc[:, -2:].values.astype(np.float32)  # Convertir en float\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier compressé\n",
    "    np.savez_compressed(output_path, X=X, Y=Y)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données depuis le fichier compressé\n",
    "    data = np.load(file_path)\n",
    "    return data['X'], data['Y']\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_path = \"data_brut/taxi.csv\"\n",
    "output_path = \"processed_data/taxi.npz\"\n",
    "\n",
    "# Créer le dossier de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Process et sauvegarde\n",
    "process_and_save_data(input_path, output_path)\n",
    "\n",
    "# Exemple d'utilisation du loader\n",
    "X, Y = load_data(output_path)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Afficher les clés disponibles\n",
    "print(\"Clés disponibles dans le fichier :\", list(data.keys()))\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        continue\n",
    "\n",
    "    # Vérification des NaN et Inf uniquement si le type est float\n",
    "    if np.issubdtype(array.dtype, np.floating):\n",
    "        nan_count = np.isnan(array).sum()\n",
    "        inf_count = np.isinf(array).sum()\n",
    "    else:\n",
    "        nan_count = inf_count = 0\n",
    "\n",
    "    print(f\"\\nClé: {key}\")\n",
    "    print(f\"  - Forme: {array.shape}\")\n",
    "    print(f\"  - Nombre de NaN: {nan_count}\")\n",
    "    print(f\"  - Nombre de Inf: {inf_count}\")\n",
    "\n",
    "    # Si le tableau est 2D, analyse plus fine\n",
    "    if array.ndim == 2:\n",
    "        # Nombre de lignes sans aucun NaN\n",
    "        rows_without_nan = np.sum(~np.isnan(array).any(axis=1))\n",
    "        print(f\"  - Nombre de lignes sans aucun NaN: {rows_without_nan}\")\n",
    "\n",
    "        # Sélectionner une colonne spécifique (ex: colonne 0)\n",
    "        col_idx = 0  # Modifier cette valeur pour une autre colonne\n",
    "        if col_idx < array.shape[1]:  # Vérifier que l'index est valide\n",
    "            nan_in_column = np.isnan(array[:, col_idx]).sum()\n",
    "            print(f\"  - Nombre de NaN dans la colonne {col_idx}: {nan_in_column}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Dictionnaire pour stocker les données modifiées\n",
    "modified_data = {}\n",
    "\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        modified_data[key] = array\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTraitement de la clé: {key}\")\n",
    "    \n",
    "    # Si c'est un tableau 2D avec des nombres flottants\n",
    "    if array.ndim == 2 and np.issubdtype(array.dtype, np.floating):\n",
    "        # Remplacement des NaN colonne par colonne\n",
    "        for col_idx in range(array.shape[1]):\n",
    "            col = array[:, col_idx]\n",
    "            if np.isnan(col).any():  # Vérifier s'il y a des NaN\n",
    "                mean_value = np.nanmean(col)  # Moyenne des valeurs non NaN\n",
    "                col[np.isnan(col)] = mean_value  # Remplacer NaN par la moyenne\n",
    "        print(f\"  - NaN remplacés par la moyenne dans toutes les colonnes.\")\n",
    "    \n",
    "    modified_data[key] = array  # Sauvegarde du tableau modifié\n",
    "\n",
    "# Enregistrer les données modifiées\n",
    "np.savez(output_path, **modified_data)\n",
    "print(f\"\\nFichier enregistré sous '{output_path}'.\")\n",
    "\n",
    "\n",
    "# https://github.com/Zhendong-Wang/Probabilistic-Conformal-Prediction/tree/main\n",
    "\n",
    "# https://github.com/Vekteur/multi-output-conformal-regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to processed_data/house.npz\n",
      "X shape: (21613, 17)\n",
      "Y shape: (21613, 2)\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (21613, 17)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 21613\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (21613, 2)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 21613\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Traitement de la clé: X\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Traitement de la clé: Y\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Fichier enregistré sous 'processed_data/house.npz'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_and_save_data(input_path, output_path):\n",
    "    # Charger le dataset depuis le fichier CSV\n",
    "    data = pd.read_csv(input_path)\n",
    "    \n",
    "    # Séparer les caractéristiques (X) et les cibles (Y)\n",
    "    # X = data.drop(data.columns[[1, 2]], axis=1).values\n",
    "    # X = data.iloc[:, 8:23].values\n",
    "    # Y = data.iloc[:, [1, 2]].values\n",
    "    data = data.select_dtypes(include=[np.number])  # Ne garde que les colonnes numériques\n",
    "    # drop the ID column\n",
    "    data = data.drop(data.columns[0], axis=1)\n",
    "    price_index = data.columns.get_loc(\"price\")\n",
    "    long_index = data.columns.get_loc(\"long\")\n",
    "\n",
    "    # Sélectionnez les colonnes \"price\" et \"long\" pour Y\n",
    "    Y = data.iloc[:, [price_index, long_index]].values.astype(np.float32)\n",
    "\n",
    "    # Sélectionnez le reste des colonnes pour X\n",
    "    X = data.drop(columns=[\"price\", \"long\"]).values.astype(np.float32)\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier compressé\n",
    "    np.savez_compressed(output_path, X=X, Y=Y)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données depuis le fichier compressé\n",
    "    data = np.load(file_path)\n",
    "    return data['X'], data['Y']\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_path = \"data_brut/house.csv\"\n",
    "output_path = \"processed_data/house.npz\"\n",
    "\n",
    "# Créer le dossier de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Process et sauvegarde\n",
    "process_and_save_data(input_path, output_path)\n",
    "\n",
    "# Exemple d'utilisation du loader\n",
    "X, Y = load_data(output_path)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Afficher les clés disponibles\n",
    "print(\"Clés disponibles dans le fichier :\", list(data.keys()))\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        continue\n",
    "\n",
    "    # Vérification des NaN et Inf uniquement si le type est float\n",
    "    if np.issubdtype(array.dtype, np.floating):\n",
    "        nan_count = np.isnan(array).sum()\n",
    "        inf_count = np.isinf(array).sum()\n",
    "    else:\n",
    "        nan_count = inf_count = 0\n",
    "\n",
    "    print(f\"\\nClé: {key}\")\n",
    "    print(f\"  - Forme: {array.shape}\")\n",
    "    print(f\"  - Nombre de NaN: {nan_count}\")\n",
    "    print(f\"  - Nombre de Inf: {inf_count}\")\n",
    "\n",
    "    # Si le tableau est 2D, analyse plus fine\n",
    "    if array.ndim == 2:\n",
    "        # Nombre de lignes sans aucun NaN\n",
    "        rows_without_nan = np.sum(~np.isnan(array).any(axis=1))\n",
    "        print(f\"  - Nombre de lignes sans aucun NaN: {rows_without_nan}\")\n",
    "\n",
    "        # Sélectionner une colonne spécifique (ex: colonne 0)\n",
    "        col_idx = 0  # Modifier cette valeur pour une autre colonne\n",
    "        if col_idx < array.shape[1]:  # Vérifier que l'index est valide\n",
    "            nan_in_column = np.isnan(array[:, col_idx]).sum()\n",
    "            print(f\"  - Nombre de NaN dans la colonne {col_idx}: {nan_in_column}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Dictionnaire pour stocker les données modifiées\n",
    "modified_data = {}\n",
    "\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        modified_data[key] = array\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTraitement de la clé: {key}\")\n",
    "    \n",
    "    # Si c'est un tableau 2D avec des nombres flottants\n",
    "    if array.ndim == 2 and np.issubdtype(array.dtype, np.floating):\n",
    "        # Remplacement des NaN colonne par colonne\n",
    "        for col_idx in range(array.shape[1]):\n",
    "            col = array[:, col_idx]\n",
    "            if np.isnan(col).any():  # Vérifier s'il y a des NaN\n",
    "                mean_value = np.nanmean(col)  # Moyenne des valeurs non NaN\n",
    "                col[np.isnan(col)] = mean_value  # Remplacer NaN par la moyenne\n",
    "        print(f\"  - NaN remplacés par la moyenne dans toutes les colonnes.\")\n",
    "    \n",
    "    modified_data[key] = array  # Sauvegarde du tableau modifié\n",
    "\n",
    "# Enregistrer les données modifiées\n",
    "np.savez(output_path, **modified_data)\n",
    "print(f\"\\nFichier enregistré sous '{output_path}'.\")\n",
    "\n",
    "\n",
    "# https://github.com/Zhendong-Wang/Probabilistic-Conformal-Prediction/tree/main\n",
    "\n",
    "# https://github.com/Vekteur/multi-output-conformal-regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to processed_data/energy.npz\n",
      "X shape: (768, 8)\n",
      "Y shape: (768, 2)\n",
      "Clés disponibles dans le fichier : ['X', 'Y']\n",
      "\n",
      "Clé: X\n",
      "  - Forme: (768, 8)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 768\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Clé: Y\n",
      "  - Forme: (768, 2)\n",
      "  - Nombre de NaN: 0\n",
      "  - Nombre de Inf: 0\n",
      "  - Nombre de lignes sans aucun NaN: 768\n",
      "  - Nombre de NaN dans la colonne 0: 0\n",
      "\n",
      "Traitement de la clé: X\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Traitement de la clé: Y\n",
      "  - NaN remplacés par la moyenne dans toutes les colonnes.\n",
      "\n",
      "Fichier enregistré sous 'processed_data/energy.npz'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_and_save_data(input_path, output_path):\n",
    "    # Charger le dataset depuis le fichier CSV\n",
    "    data = pd.read_csv(input_path)\n",
    "    \n",
    "    # Séparer les caractéristiques (X) et les cibles (Y)\n",
    "    # X = data.drop(data.columns[[1, 2]], axis=1).values\n",
    "    # X = data.iloc[:, 8:23].values\n",
    "    # Y = data.iloc[:, [1, 2]].values\n",
    "    data = data.select_dtypes(include=[np.number])  # Ne garde que les colonnes numériques\n",
    "    X = data.iloc[:, :-2].values.astype(np.float32)  # Convertir en float\n",
    "    Y = data.iloc[:, -2:].values.astype(np.float32)  # Convertir en float\n",
    "    \n",
    "    # Sauvegarder les données dans un fichier compressé\n",
    "    np.savez_compressed(output_path, X=X, Y=Y)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données depuis le fichier compressé\n",
    "    data = np.load(file_path)\n",
    "    return data['X'], data['Y']\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_path = \"data_brut/energy.csv\"\n",
    "output_path = \"processed_data/energy.npz\"\n",
    "\n",
    "# Créer le dossier de sortie si nécessaire\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Process et sauvegarde\n",
    "process_and_save_data(input_path, output_path)\n",
    "\n",
    "# Exemple d'utilisation du loader\n",
    "X, Y = load_data(output_path)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Afficher les clés disponibles\n",
    "print(\"Clés disponibles dans le fichier :\", list(data.keys()))\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        continue\n",
    "\n",
    "    # Vérification des NaN et Inf uniquement si le type est float\n",
    "    if np.issubdtype(array.dtype, np.floating):\n",
    "        nan_count = np.isnan(array).sum()\n",
    "        inf_count = np.isinf(array).sum()\n",
    "    else:\n",
    "        nan_count = inf_count = 0\n",
    "\n",
    "    print(f\"\\nClé: {key}\")\n",
    "    print(f\"  - Forme: {array.shape}\")\n",
    "    print(f\"  - Nombre de NaN: {nan_count}\")\n",
    "    print(f\"  - Nombre de Inf: {inf_count}\")\n",
    "\n",
    "    # Si le tableau est 2D, analyse plus fine\n",
    "    if array.ndim == 2:\n",
    "        # Nombre de lignes sans aucun NaN\n",
    "        rows_without_nan = np.sum(~np.isnan(array).any(axis=1))\n",
    "        print(f\"  - Nombre de lignes sans aucun NaN: {rows_without_nan}\")\n",
    "\n",
    "        # Sélectionner une colonne spécifique (ex: colonne 0)\n",
    "        col_idx = 0  # Modifier cette valeur pour une autre colonne\n",
    "        if col_idx < array.shape[1]:  # Vérifier que l'index est valide\n",
    "            nan_in_column = np.isnan(array[:, col_idx]).sum()\n",
    "            print(f\"  - Nombre de NaN dans la colonne {col_idx}: {nan_in_column}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "data = np.load(output_path)\n",
    "\n",
    "# Dictionnaire pour stocker les données modifiées\n",
    "modified_data = {}\n",
    "\n",
    "for key in data.files:\n",
    "    array = data[key]\n",
    "    \n",
    "    if not isinstance(array, np.ndarray):\n",
    "        print(f\"{key}: Ce n'est pas un tableau numpy.\")\n",
    "        modified_data[key] = array\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTraitement de la clé: {key}\")\n",
    "    \n",
    "    # Si c'est un tableau 2D avec des nombres flottants\n",
    "    if array.ndim == 2 and np.issubdtype(array.dtype, np.floating):\n",
    "        # Remplacement des NaN colonne par colonne\n",
    "        for col_idx in range(array.shape[1]):\n",
    "            col = array[:, col_idx]\n",
    "            if np.isnan(col).any():  # Vérifier s'il y a des NaN\n",
    "                mean_value = np.nanmean(col)  # Moyenne des valeurs non NaN\n",
    "                col[np.isnan(col)] = mean_value  # Remplacer NaN par la moyenne\n",
    "        print(f\"  - NaN remplacés par la moyenne dans toutes les colonnes.\")\n",
    "    \n",
    "    modified_data[key] = array  # Sauvegarde du tableau modifié\n",
    "\n",
    "# Enregistrer les données modifiées\n",
    "np.savez(output_path, **modified_data)\n",
    "print(f\"\\nFichier enregistré sous '{output_path}'.\")\n",
    "\n",
    "\n",
    "# https://github.com/Zhendong-Wang/Probabilistic-Conformal-Prediction/tree/main\n",
    "\n",
    "# https://github.com/Vekteur/multi-output-conformal-regression\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
