{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_and_format_results_one_file(file_path, special_word):\n",
    "    pkl_file = os.path.basename(file_path)\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "            if isinstance(results, dict):\n",
    "                mean_results = {}\n",
    "                std_results = {}\n",
    "                for key in results[0].keys():\n",
    "                    if special_word in key.lower():  # Vérifie si \"volume\" est dans la clé\n",
    "                        # Extract values for the current key across experiments\n",
    "                        values = [results[exp][key] for exp in results]\n",
    "\n",
    "                        # Remove the minimum and maximum values\n",
    "                        values_sorted = sorted(values)\n",
    "                        values_trimmed = values_sorted[1:-1]  # Exclude first (min) and last (max)\n",
    "\n",
    "                        # Calculate the mean of the remaining values\n",
    "                        mean_results[key] = np.mean(values_trimmed)\n",
    "                        std_results[key] = np.std(values_trimmed, ddof=1)  # Sample std deviation\n",
    "                \n",
    "                return mean_results, std_results\n",
    "            else:\n",
    "                print(f\"Warning: {pkl_file} does not contain a dictionary.\")\n",
    "                return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {pkl_file}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def load_and_format_volume_results(folder_path, alpha, n_numbers=3):\n",
    "    \"\"\"\n",
    "    Load and format the contents of all .pkl files in the specified folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    pkl_files = [f for f in os.listdir(folder_path) if f.endswith('.pkl') and 'tab' not in f]\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(\"No .pkl files found in the folder.\")\n",
    "        return\n",
    "    \n",
    "    all_results = {}\n",
    "    for pkl_file in pkl_files:\n",
    "        file_path = os.path.join(folder_path, pkl_file)\n",
    "        mean_results, std_results = load_and_format_results_one_file(file_path, \"volume\")\n",
    "        if mean_results is not None:\n",
    "            all_results[pkl_file] = (mean_results, std_results)\n",
    "    \n",
    "    # Generate LaTeX formatted output\n",
    "    datasets = list(all_results.keys())\n",
    "    keys = list(next(iter(all_results.values()))[0].keys())  # Get volume-related keys\n",
    "    \n",
    "    keys = [\"volume_hyper_rectangle\", \"volume_covariance\", \"volume_local_covariance\", \"volume_ellipsoid\"]\n",
    "\n",
    "    latex_output = \"Dataset \" + \" & \" + \" & \".join(keys) + \"\\\\\\\\ \\\\hline\\n\"\n",
    "    for dataset in sorted(datasets):  # Sorting datasets alphabetically\n",
    "        if f\"alpha_{alpha}\" in dataset.lower():\n",
    "            row = f\"{dataset[:10].replace('_', ' ')} \"  # Display only the first 10 characters of dataset with underscores replaced by spaces\n",
    "            mean_results, std_results = all_results[dataset]\n",
    "            for key in keys:\n",
    "                # Find the smallest value in the row for the current dataset\n",
    "                values = [mean_results[k] for k in keys]\n",
    "                min_value = min(values)\n",
    "                \n",
    "                # Format the result, applying \\textbf to the smallest value\n",
    "                if mean_results[key] == min_value:\n",
    "                    formatted_result = f\"\\\\textbf{{{mean_results[key]:.{n_numbers}f}}} \\pm {std_results[key]:.{n_numbers}f}\"\n",
    "                else:\n",
    "                    formatted_result = f\"{mean_results[key]:.{n_numbers}f} \\pm {std_results[key]:.{n_numbers}f}\"\n",
    "                \n",
    "                row += f\" & ${formatted_result}$ \"\n",
    "            row += \"\\\\\\\\ \\\\hline\\n\"\n",
    "            latex_output += row\n",
    "\n",
    "    print(latex_output)\n",
    "\n",
    "def load_and_format_coverage_results(folder_path, alpha, n_numbers=3):\n",
    "    \"\"\"\n",
    "    Load and format the contents of all .pkl files in the specified folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    pkl_files = [f for f in os.listdir(folder_path) if f.endswith('.pkl') and 'tab' not in f]\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(\"No .pkl files found in the folder.\")\n",
    "        return\n",
    "    \n",
    "    all_results = {}\n",
    "    for pkl_file in pkl_files:\n",
    "        file_path = os.path.join(folder_path, pkl_file)\n",
    "        mean_results, std_results = load_and_format_results_one_file(file_path, \"coverage\")\n",
    "        if mean_results is not None:\n",
    "            all_results[pkl_file] = (mean_results, std_results)\n",
    "    \n",
    "    # Generate LaTeX formatted output\n",
    "    datasets = list(all_results.keys())\n",
    "    keys = list(next(iter(all_results.values()))[0].keys())  # Get volume-related keys\n",
    "    \n",
    "    keys = [\"coverage_hyper_rectangle\", \"coverage_covariance\", \"coverage_local_covariance\", \"coverage_ellipsoid\"]\n",
    "\n",
    "    latex_output = \"Dataset \" + \" & \" + \" & \".join(keys) + \"\\\\\\\\ \\\\hline\\n\"\n",
    "    for dataset in sorted(datasets):  # Sorting datasets alphabetically\n",
    "        if f\"alpha_{alpha}\" in dataset.lower():\n",
    "            row = f\"{dataset[:10].replace('_', ' ')} \"  # Display only the first 10 characters of dataset with underscores replaced by spaces\n",
    "            mean_results, std_results = all_results[dataset]\n",
    "            for key in keys:\n",
    "                # Find the smallest value in the row for the current dataset\n",
    "                values = [mean_results[k] for k in keys]\n",
    "                min_value = min(values)\n",
    "                \n",
    "                # Format the result, applying \\textbf to the smallest value\n",
    "                \n",
    "                formatted_result = f\"{mean_results[key]:.{n_numbers}f} \\pm {std_results[key]:.{n_numbers}f}\"\n",
    "                \n",
    "                row += f\" & ${formatted_result}$ \"\n",
    "            row += \"\\\\\\\\ \\\\hline\\n\"\n",
    "            latex_output += row\n",
    "\n",
    "    print(latex_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder 'new_synthetic_results' does not exist.\n",
      "\n",
      "\n",
      "\n",
      "The folder 'new_synthetic_results' does not exist.\n",
      "\n",
      "\n",
      "\n",
      "The folder 'new_synthetic_results' does not exist.\n",
      "\n",
      "\n",
      "\n",
      "The folder 'new_synthetic_results' does not exist.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load_and_format_volume_results(\"new_results\", alpha = 0.1, n_numbers=6)\n",
    "# print(\"\\n\\n\")\n",
    "# load_and_format_coverage_results(\"new_results\", alpha = 0.1)\n",
    "# print(\"\\n\\n\")\n",
    "# load_and_format_volume_results(\"new_results\", alpha = 0.01, n_numbers=3)\n",
    "# print(\"\\n\\n\")\n",
    "# load_and_format_coverage_results(\"new_results\", alpha = 0.01)\n",
    "# print(\"\\n\\n\")\n",
    "load_and_format_volume_results(\"new_synthetic_results\", alpha = 0.1, n_numbers=0)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_coverage_results(\"new_synthetic_results\", alpha = 0.1)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_volume_results(\"new_synthetic_results\", alpha = 0.01, n_numbers=0)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_coverage_results(\"new_synthetic_results\", alpha = 0.01)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_and_format_results_one_file(file_path, special_word):\n",
    "    pkl_file = os.path.basename(file_path)\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "            if isinstance(results, dict):\n",
    "                mean_results = {}\n",
    "                std_results = {}\n",
    "                for key in results[0].keys():\n",
    "                    if special_word in key.lower():  # Vérifie si \"volume\" est dans la clé\n",
    "                        # Extract values for the current key across experiments\n",
    "                        if special_word == \"volume\":\n",
    "                            values = [results[exp][key]/results[exp][\"volume_ellipsoid\"] for exp in results]\n",
    "                        else:\n",
    "                            values = [100*results[exp][key] for exp in results]\n",
    "\n",
    "                        # Remove the minimum and maximum values\n",
    "                        values_sorted = sorted(values)\n",
    "                        values_trimmed = values_sorted[1:-1]  # Exclude first (min) and last (max)\n",
    "\n",
    "                        # Calculate the mean of the remaining values\n",
    "                        mean_results[key] = np.mean(values_trimmed)\n",
    "                        std_results[key] = np.std(values_trimmed, ddof=1)  # Sample std deviation\n",
    "                \n",
    "                return mean_results, std_results\n",
    "            else:\n",
    "                print(f\"Warning: {pkl_file} does not contain a dictionary.\")\n",
    "                return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {pkl_file}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def load_and_format_volume_results(folder_path, alpha, n_numbers=3):\n",
    "    \"\"\"\n",
    "    Load and format the contents of all .pkl files in the specified folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    pkl_files = [f for f in os.listdir(folder_path) if f.endswith('.pkl') and 'tab' not in f]\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(\"No .pkl files found in the folder.\")\n",
    "        return\n",
    "    \n",
    "    all_results = {}\n",
    "    for pkl_file in pkl_files:\n",
    "        file_path = os.path.join(folder_path, pkl_file)\n",
    "        mean_results, std_results = load_and_format_results_one_file(file_path, \"volume\")\n",
    "        if mean_results is not None:\n",
    "            all_results[pkl_file] = (mean_results, std_results)\n",
    "    \n",
    "    # Generate LaTeX formatted output\n",
    "    datasets = list(all_results.keys())\n",
    "    keys = list(next(iter(all_results.values()))[0].keys())  # Get volume-related keys\n",
    "    \n",
    "    keys = [\"volume_hyper_rectangle\", \"volume_covariance\", \"volume_local_covariance\", \"volume_ellipsoid\"]\n",
    "\n",
    "    latex_output = \"Dataset \" + \" & \" + \" & \".join(keys) + \"\\\\\\\\ \\\\hline\\n\"\n",
    "    for dataset in sorted(datasets):  # Sorting datasets alphabetically\n",
    "        if f\"alpha_{alpha}\" in dataset.lower():\n",
    "            row = f\"{dataset[:10].replace('_', ' ')} \"  # Display only the first 10 characters of dataset with underscores replaced by spaces\n",
    "            mean_results, std_results = all_results[dataset]\n",
    "            for key in keys:\n",
    "                # Find the smallest value in the row for the current dataset\n",
    "                values = [mean_results[k] for k in keys]\n",
    "                min_value = min(values)\n",
    "                \n",
    "                # Format the result, applying \\textbf to the smallest value\n",
    "                if mean_results[key] == min_value:\n",
    "                    formatted_result = f\"\\\\textbf{{{mean_results[key]:.{n_numbers}f}}} \\pm {std_results[key]:.{n_numbers}f}\"\n",
    "                else:\n",
    "                    formatted_result = f\"{mean_results[key]:.{n_numbers}f} \\pm {std_results[key]:.{n_numbers}f}\"\n",
    "                \n",
    "                row += f\" & ${formatted_result}$ \"\n",
    "            row += \"\\\\\\\\ \\\\hline\\n\"\n",
    "            latex_output += row\n",
    "\n",
    "    print(latex_output)\n",
    "\n",
    "def load_and_format_coverage_results(folder_path, alpha, n_numbers=3, n_numbers_std=1):\n",
    "    \"\"\"\n",
    "    Load and format the contents of all .pkl files in the specified folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    pkl_files = [f for f in os.listdir(folder_path) if f.endswith('.pkl') and 'tab' not in f]\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(\"No .pkl files found in the folder.\")\n",
    "        return\n",
    "    \n",
    "    all_results = {}\n",
    "    for pkl_file in pkl_files:\n",
    "        file_path = os.path.join(folder_path, pkl_file)\n",
    "        mean_results, std_results = load_and_format_results_one_file(file_path, \"coverage\")\n",
    "        if mean_results is not None:\n",
    "            all_results[pkl_file] = (mean_results, std_results)\n",
    "    \n",
    "    # Generate LaTeX formatted output\n",
    "    datasets = list(all_results.keys())\n",
    "    keys = list(next(iter(all_results.values()))[0].keys())  # Get volume-related keys\n",
    "    \n",
    "    keys = [\"coverage_hyper_rectangle\", \"coverage_covariance\", \"coverage_local_covariance\", \"coverage_ellipsoid\"]\n",
    "\n",
    "    latex_output = \"Dataset \" + \" & \" + \" & \".join(keys) + \"\\\\\\\\ \\\\hline\\n\"\n",
    "    for dataset in sorted(datasets):  # Sorting datasets alphabetically\n",
    "        if f\"alpha_{alpha}\" in dataset.lower():\n",
    "            row = f\"{dataset[:10].replace('_', ' ')} \"  # Display only the first 10 characters of dataset with underscores replaced by spaces\n",
    "            mean_results, std_results = all_results[dataset]\n",
    "            for key in keys:\n",
    "                # Find the smallest value in the row for the current dataset\n",
    "                values = [mean_results[k] for k in keys]\n",
    "                min_value = min(values)\n",
    "                \n",
    "                # Format the result, applying \\textbf to the smallest value\n",
    "                \n",
    "                # formatted_result = f\"{mean_results[key]:.{n_numbers}f} \\pm {std_results[key]:.{n_numbers}f}\"\n",
    "                formatted_result = f\"{mean_results[key]:.{n_numbers}f} \\pm {std_results[key]:.{n_numbers_std}f}\"\n",
    "                \n",
    "                row += f\" & ${formatted_result}$ \"\n",
    "            row += \"\\\\\\\\ \\\\hline\\n\"\n",
    "            latex_output += row\n",
    "\n",
    "    print(latex_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset  & volume_hyper_rectangle & volume_covariance & volume_local_covariance & volume_ellipsoid\\\\ \\hline\n",
      "Bias corre  & $1.00 \\pm 0.23$  & $\\textbf{0.96} \\pm 0.23$  & $1.25 \\pm 0.33$  & $1.00 \\pm 0.00$ \\\\ \\hline\n",
      "casp01 CAS  & $1.12 \\pm 0.03$  & $1.33 \\pm 0.02$  & $1.19 \\pm 0.03$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "energy01 e  & $1.81 \\pm 0.57$  & $1.27 \\pm 0.26$  & $1.27 \\pm 0.26$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "house01 ho  & $1.07 \\pm 0.06$  & $1.10 \\pm 0.03$  & $1.09 \\pm 0.03$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "rf101 rf1   & $3.23 \\pm 2.36$  & $3.32 \\pm 1.71$  & $60.21 \\pm 36.39$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "rf201 rf2   & $91.24 \\pm 41.98$  & $4.18 \\pm 1.42$  & $5.95 \\pm 2.10$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "scm1d 10 a  & $23704.13 \\pm 26820.17$  & $17.62 \\pm 11.81$  & $17.62 \\pm 11.81$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "scm20d 10   & $2715970.65 \\pm 3639458.87$  & $29273.46 \\pm 38766.97$  & $29273.46 \\pm 38766.97$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "taxi01 tax  & $1.20 \\pm 0.02$  & $1.16 \\pm 0.02$  & $1.11 \\pm 0.02$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset  & coverage_hyper_rectangle & coverage_covariance & coverage_local_covariance & coverage_ellipsoid\\\\ \\hline\n",
      "Bias corre  & $90.5 \\pm 1.1$  & $90.2 \\pm 1.3$  & $90.1 \\pm 1.0$  & $90.3 \\pm 0.8$ \\\\ \\hline\n",
      "casp01 CAS  & $89.9 \\pm 0.5$  & $90.1 \\pm 0.3$  & $89.9 \\pm 0.4$  & $90.1 \\pm 0.4$ \\\\ \\hline\n",
      "energy01 e  & $89.3 \\pm 2.6$  & $91.4 \\pm 3.8$  & $91.4 \\pm 3.8$  & $90.7 \\pm 2.3$ \\\\ \\hline\n",
      "house01 ho  & $90.3 \\pm 0.8$  & $90.3 \\pm 0.6$  & $90.6 \\pm 0.7$  & $90.3 \\pm 0.7$ \\\\ \\hline\n",
      "rf101 rf1   & $89.9 \\pm 1.0$  & $89.3 \\pm 1.8$  & $89.3 \\pm 1.1$  & $89.4 \\pm 1.4$ \\\\ \\hline\n",
      "rf201 rf2   & $89.8 \\pm 0.7$  & $90.1 \\pm 1.2$  & $90.3 \\pm 1.1$  & $89.9 \\pm 1.0$ \\\\ \\hline\n",
      "scm1d 10 a  & $90.9 \\pm 0.8$  & $90.3 \\pm 1.0$  & $90.3 \\pm 1.0$  & $91.0 \\pm 1.2$ \\\\ \\hline\n",
      "scm20d 10   & $90.4 \\pm 0.8$  & $90.2 \\pm 0.7$  & $90.2 \\pm 0.7$  & $90.3 \\pm 0.8$ \\\\ \\hline\n",
      "taxi01 tax  & $90.0 \\pm 0.3$  & $90.0 \\pm 0.3$  & $89.9 \\pm 0.4$  & $90.0 \\pm 0.3$ \\\\ \\hline\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset  & volume_hyper_rectangle & volume_covariance & volume_local_covariance & volume_ellipsoid\\\\ \\hline\n",
      "Bias corre  & $1.10 \\pm 0.27$  & $1.21 \\pm 0.24$  & $2.05 \\pm 0.48$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "casp001 CA  & $1.32 \\pm 0.09$  & $1.60 \\pm 0.19$  & $1.62 \\pm 0.29$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "energy001   & $2.43 \\pm 1.31$  & $2.79 \\pm 1.65$  & $2.79 \\pm 1.65$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "house001 h  & $1.39 \\pm 0.19$  & $1.77 \\pm 0.14$  & $2.05 \\pm 0.17$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "rf1001 rf1  & $5.78 \\pm 4.34$  & $31.79 \\pm 34.36$  & $46.22 \\pm 38.67$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "rf2001 rf2  & $301.65 \\pm 318.20$  & $169.80 \\pm 190.13$  & $33.79 \\pm 56.98$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "scm1d 10 a  & $39.48 \\pm 56.03$  & $1.36 \\pm 1.44$  & $1.36 \\pm 1.44$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "scm20d 10   & $1220.93 \\pm 1086.33$  & $3.67 \\pm 1.49$  & $3.67 \\pm 1.49$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "taxi001 ta  & $1.08 \\pm 0.02$  & $1.45 \\pm 0.09$  & $1.19 \\pm 0.04$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset  & coverage_hyper_rectangle & coverage_covariance & coverage_local_covariance & coverage_ellipsoid\\\\ \\hline\n",
      "Bias corre  & $99.1 \\pm 0.2$  & $99.3 \\pm 0.2$  & $99.1 \\pm 0.4$  & $99.4 \\pm 0.4$ \\\\ \\hline\n",
      "casp001 CA  & $99.2 \\pm 0.1$  & $99.0 \\pm 0.1$  & $99.0 \\pm 0.1$  & $99.1 \\pm 0.1$ \\\\ \\hline\n",
      "energy001   & $99.8 \\pm 0.4$  & $99.8 \\pm 0.4$  & $99.8 \\pm 0.4$  & $99.4 \\pm 0.8$ \\\\ \\hline\n",
      "house001 h  & $99.1 \\pm 0.2$  & $99.0 \\pm 0.3$  & $99.1 \\pm 0.2$  & $99.0 \\pm 0.2$ \\\\ \\hline\n",
      "rf1001 rf1  & $99.0 \\pm 0.3$  & $99.0 \\pm 0.3$  & $99.0 \\pm 0.5$  & $99.0 \\pm 0.3$ \\\\ \\hline\n",
      "rf2001 rf2  & $99.0 \\pm 0.4$  & $99.0 \\pm 0.5$  & $99.1 \\pm 0.1$  & $99.2 \\pm 0.3$ \\\\ \\hline\n",
      "scm1d 10 a  & $99.2 \\pm 0.3$  & $99.3 \\pm 0.3$  & $99.3 \\pm 0.3$  & $99.3 \\pm 0.3$ \\\\ \\hline\n",
      "scm20d 10   & $99.1 \\pm 0.2$  & $99.3 \\pm 0.2$  & $99.3 \\pm 0.2$  & $99.1 \\pm 0.3$ \\\\ \\hline\n",
      "taxi001 ta  & $98.9 \\pm 0.1$  & $98.9 \\pm 0.1$  & $98.9 \\pm 0.1$  & $98.9 \\pm 0.1$ \\\\ \\hline\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset  & volume_hyper_rectangle & volume_covariance & volume_local_covariance & volume_ellipsoid\\\\ \\hline\n",
      "exp fixed   & $2.63 \\pm 0.20$  & $1.40 \\pm 0.10$  & $1.30 \\pm 0.10$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "exp t 01 e  & $2.57 \\pm 0.21$  & $1.57 \\pm 0.09$  & $1.52 \\pm 0.05$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "gau fixed   & $2.87 \\pm 0.27$  & $1.29 \\pm 0.03$  & $1.20 \\pm 0.03$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "gaussian t  & $2.34 \\pm 0.07$  & $1.61 \\pm 0.09$  & $1.32 \\pm 0.02$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset  & coverage_hyper_rectangle & coverage_covariance & coverage_local_covariance & coverage_ellipsoid\\\\ \\hline\n",
      "exp fixed   & $89.6 \\pm 0.7$  & $89.7 \\pm 0.6$  & $89.8 \\pm 0.5$  & $89.7 \\pm 0.6$ \\\\ \\hline\n",
      "exp t 01 e  & $89.6 \\pm 0.7$  & $89.9 \\pm 0.7$  & $89.9 \\pm 0.7$  & $90.0 \\pm 0.8$ \\\\ \\hline\n",
      "gau fixed   & $89.9 \\pm 0.6$  & $90.0 \\pm 0.5$  & $89.8 \\pm 0.6$  & $89.7 \\pm 0.7$ \\\\ \\hline\n",
      "gaussian t  & $89.8 \\pm 0.5$  & $90.0 \\pm 0.4$  & $89.8 \\pm 0.4$  & $89.7 \\pm 0.3$ \\\\ \\hline\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset  & volume_hyper_rectangle & volume_covariance & volume_local_covariance & volume_ellipsoid\\\\ \\hline\n",
      "exp fixed   & $2.77 \\pm 0.09$  & $1.37 \\pm 0.06$  & $1.29 \\pm 0.08$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "exp t 001   & $2.77 \\pm 0.43$  & $2.73 \\pm 0.28$  & $1.28 \\pm 0.12$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "gau t 001   & $2.80 \\pm 0.43$  & $3.32 \\pm 0.34$  & $1.02 \\pm 0.08$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "gaussian f  & $3.29 \\pm 0.30$  & $1.55 \\pm 0.19$  & $1.22 \\pm 0.06$  & $\\textbf{1.00} \\pm 0.00$ \\\\ \\hline\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset  & coverage_hyper_rectangle & coverage_covariance & coverage_local_covariance & coverage_ellipsoid\\\\ \\hline\n",
      "exp fixed   & $98.9 \\pm 0.1$  & $98.8 \\pm 0.2$  & $98.8 \\pm 0.2$  & $98.8 \\pm 0.1$ \\\\ \\hline\n",
      "exp t 001   & $99.1 \\pm 0.2$  & $99.0 \\pm 0.3$  & $98.8 \\pm 0.2$  & $98.8 \\pm 0.2$ \\\\ \\hline\n",
      "gau t 001   & $99.0 \\pm 0.2$  & $98.8 \\pm 0.2$  & $99.0 \\pm 0.2$  & $98.9 \\pm 0.1$ \\\\ \\hline\n",
      "gaussian f  & $99.0 \\pm 0.1$  & $98.9 \\pm 0.2$  & $98.9 \\pm 0.1$  & $98.9 \\pm 0.3$ \\\\ \\hline\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_and_format_volume_results(\"volume\", alpha = 0.1, n_numbers=2)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_coverage_results(\"volume\", alpha = 0.1, n_numbers=1, n_numbers_std=1)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_volume_results(\"volume\", alpha = 0.01, n_numbers=2)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_coverage_results(\"volume\", alpha = 0.01, n_numbers=1, n_numbers_std=1)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_volume_results(\"volume_s\", alpha = 0.1, n_numbers=2)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_coverage_results(\"volume_s\", alpha = 0.1, n_numbers=1, n_numbers_std=1)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_volume_results(\"volume_s\", alpha = 0.01, n_numbers=2)\n",
    "print(\"\\n\\n\")\n",
    "load_and_format_coverage_results(\"volume_s\", alpha = 0.01, n_numbers=1, n_numbers_std=1)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
